#!/usr/bin/env python3
from __future__ import annotations

import argparse
import hashlib
import json
import re
import platform
import shutil
import subprocess
import sys
import time
from pathlib import Path


ROOT = Path(__file__).resolve().parent.parent
DIST_DIR = ROOT / "dist"
REPORT_DIR = ROOT / "reports" / "release-build"
C_DIR = ROOT / "c"
ARCH_ALIASES = {
    "aarch64": "arm64",
    "amd64": "x86_64",
}
REQUIRED_ARCH = "arm64"


def run_gate(name: str, cmd: list[str], gates: list[dict[str, object]], capture_output: bool = False) -> subprocess.CompletedProcess[str]:
    print(f"[release-build] RUN {name}: {' '.join(cmd)}", flush=True)
    t0 = time.time()
    proc = subprocess.run(
        cmd,
        cwd=str(ROOT),
        text=True,
        stdout=subprocess.PIPE if capture_output else None,
        stderr=subprocess.STDOUT if capture_output else None,
    )
    duration_ms = int((time.time() - t0) * 1000)
    gate = {
        "name": name,
        "command": " ".join(cmd),
        "exit_code": proc.returncode,
        "duration_ms": duration_ms,
    }
    gates.append(gate)
    if proc.returncode != 0:
        if capture_output and proc.stdout:
            print(proc.stdout, file=sys.stderr, end="")
        print(f"[release-build] FAIL {name} ({duration_ms} ms)", file=sys.stderr, flush=True)
        raise SystemExit(proc.returncode)
    if capture_output and proc.stdout:
        print(proc.stdout, end="")
    print(f"[release-build] OK {name} ({duration_ms} ms)", flush=True)
    return proc


def read_version(cmd: list[str]) -> str:
    try:
        proc = subprocess.run(cmd, cwd=str(ROOT), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    except FileNotFoundError:
        return "missing"
    if proc.returncode != 0:
        return f"error(rc={proc.returncode})"
    out = proc.stdout.strip().splitlines()
    return out[0].strip() if out else "unknown"


def sha256_file(path: Path) -> str:
    h = hashlib.sha256()
    with path.open("rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()


def git_commit() -> str:
    proc = subprocess.run(["git", "rev-parse", "HEAD"], cwd=str(ROOT), stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, text=True)
    if proc.returncode != 0:
        return "unknown"
    return proc.stdout.strip()


def normalize_arch(raw_arch: str) -> str:
    arch = raw_arch.strip().lower()
    return ARCH_ALIASES.get(arch, arch)


def detect_host_arch() -> str:
    proc = subprocess.run(["uname", "-m"], cwd=str(ROOT), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    if proc.returncode != 0:
        raise SystemExit(f"[release-build] ERROR uname -m failed: {proc.stdout.strip()}")
    return normalize_arch(proc.stdout.strip())


def compiler_target_triple(cc_value: str) -> str:
    cc_cmd = cc_value.strip() or "cc"
    cmd = [cc_cmd]
    if platform.system() == "Darwin":
        cmd.extend(["-arch", REQUIRED_ARCH])
    cmd.extend(["-v", "-E", "-x", "c", "/dev/null"])
    try:
        proc = subprocess.run(cmd, cwd=str(ROOT), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    except FileNotFoundError:
        return "missing"
    out = proc.stdout or ""
    m = re.search(r"^Target:\s*(.+)$", out, flags=re.MULTILINE)
    if m:
        return m.group(1).strip()
    if proc.returncode != 0:
        return f"error(rc={proc.returncode}): {proc.stdout.strip()}"
    return "unknown"


def object_archs(path: Path) -> set[str]:
    try:
        proc = subprocess.run(["file", str(path)], cwd=str(ROOT), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    except FileNotFoundError:
        return set()
    if proc.returncode != 0:
        return set()
    return set(re.findall(r"\b(arm64|x86_64)\b", proc.stdout))


def stale_object_paths(target_arch: str) -> list[Path]:
    candidates = []
    candidates.extend(C_DIR.rglob("*.o"))
    candidates.extend((ROOT / "third_party" / "mcpp").glob("*.o"))
    stale = []
    for obj in candidates:
        archs = object_archs(obj)
        if archs and target_arch not in archs:
            stale.append(obj)
    return stale


def binary_arch(path: Path) -> str:
    try:
        proc = subprocess.run(["lipo", "-info", str(path)], cwd=str(ROOT), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    except FileNotFoundError:
        proc = None
    if proc and proc.returncode == 0:
        return proc.stdout.strip()
    proc = subprocess.run(["file", str(path)], cwd=str(ROOT), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    return proc.stdout.strip()


def main() -> int:
    parser = argparse.ArgumentParser(description="Build ProtoScript2 release artifacts and verify release gates.")
    parser.add_argument("--version", default="1.0.0", help="Release version (default: 1.0.0)")
    parser.add_argument("--nightly", action="store_true", help="Use full robustness gate instead of sanitizer smoke.")
    args = parser.parse_args()

    host_arch = detect_host_arch()
    if platform.system() != "Darwin":
        print(f"[release-build] ERROR unsupported OS for v1.0.0 release path: {platform.system()} (requires macOS)", file=sys.stderr)
        return 2
    if host_arch != REQUIRED_ARCH:
        print(f"[release-build] ERROR unsupported host architecture from uname -m: {host_arch} (requires {REQUIRED_ARCH})", file=sys.stderr)
        return 2

    print(f"[release-build] detected host architecture (uname -m): {host_arch}")

    release_version = args.version
    target_arch = REQUIRED_ARCH
    platform_tag = f"{platform.system().lower().replace('darwin', 'macos')}-{REQUIRED_ARCH}"
    release_name = f"protoscript2-v{release_version}-{platform_tag}"
    release_dir = DIST_DIR / release_name

    DIST_DIR.mkdir(parents=True, exist_ok=True)
    REPORT_DIR.mkdir(parents=True, exist_ok=True)

    if release_dir.exists():
        shutil.rmtree(release_dir)
    (release_dir / "bin").mkdir(parents=True, exist_ok=True)

    gates: list[dict[str, object]] = []

    build_vars_proc = run_gate("build_vars", ["make", "-C", "c", "CC=cc", "print-build-vars"], gates, capture_output=True)
    build_vars = {}
    for line in (build_vars_proc.stdout or "").splitlines():
        if "=" in line:
            key, value = line.split("=", 1)
            build_vars[key.strip()] = value.strip()
    cc_value = build_vars.get("CC", "cc")
    target_triple = compiler_target_triple(cc_value)
    print(f"[release-build] compiler target triple: {target_triple}")

    clean_reasons: list[str] = []
    stale = stale_object_paths(REQUIRED_ARCH)
    if stale:
        clean_reasons.append(f"found {len(stale)} stale object(s) with mismatched architecture")
        for path in stale[:10]:
            print(f"[release-build] stale object: {path.relative_to(ROOT)}")
        if len(stale) > 10:
            print(f"[release-build] ... and {len(stale) - 10} more stale object(s)")
    if clean_reasons:
        print(f"[release-build] architecture mismatch detected; cleaning C artifacts: {'; '.join(clean_reasons)}")
        run_gate("clean_c_arch_mismatch", ["make", "-C", "c", "CC=cc", "clean"], gates)
        run_gate("clean_mcpp_arch_mismatch", ["make", "-C", "third_party/mcpp", "clean"], gates)

    run_gate("build_c", ["make", "-C", "c", "CC=cc"], gates)

    post_stale = stale_object_paths(REQUIRED_ARCH)
    if post_stale:
        print("[release-build] ERROR architecture mismatch after build; refusing mixed object set:", file=sys.stderr)
        for path in post_stale:
            print(f"[release-build]   {path.relative_to(ROOT)}", file=sys.stderr)
        return 2

    run_gate("orchestrator_full", ["./tools/test-orchestrator", "--full", "--summary"], gates)
    run_gate("emitc_conformance_runtime", ["tests/run_runtime_crosscheck.sh"], gates)

    if args.nightly:
        run_gate("robustness_full", ["tests/run_robustness.sh"], gates)
    else:
        run_gate("sanitizer_smoke", ["tests/run_sanitizer_smoke.sh"], gates)

    artifacts_src = [
        ROOT / "c" / "ps",
        ROOT / "c" / "pscc",
        ROOT / "bin" / "protoscriptc",
        ROOT / "tests" / "manifest.json",
        ROOT / "tests" / "spec_refs.json",
    ]

    print("[release-build] packaging source discovery: explicit static list (no glob)")
    print("[release-build] packaging source templates:")
    print("[release-build]   ROOT / 'c' / 'ps'")
    print("[release-build]   ROOT / 'c' / 'pscc'")
    print("[release-build]   ROOT / 'bin' / 'protoscriptc'")
    print("[release-build]   ROOT / 'tests' / 'manifest.json'")
    print("[release-build]   ROOT / 'tests' / 'spec_refs.json'")
    print("[release-build] selected packaging sources:")
    for src in artifacts_src:
        print(f"[release-build]   {src}")

    required_sources = {ROOT / "c" / "ps", ROOT / "c" / "pscc"}
    selected_sources = set(artifacts_src)
    missing_required = sorted(required_sources - selected_sources)
    if missing_required:
        print("[release-build] ERROR required binary source(s) missing from packaging list:", file=sys.stderr)
        for path in missing_required:
            print(f"[release-build]   {path}", file=sys.stderr)
        return 2

    copied: list[Path] = []
    for src in artifacts_src:
        print(f"[release-build] packaging candidate src: {src}")
        if not src.exists():
            print(f"[release-build] ERROR missing artifact source: {src}", file=sys.stderr)
            return 2
        rel_dst = (Path("bin") / src.name) if src.parent.name in {"c", "bin"} else Path(src.name)
        dst = release_dir / rel_dst
        dst.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(src, dst)
        print(f"[release-build] copied: {src} -> {dst}")
        copied.append(dst)

    print("[release-build] copied artifact list:")
    for dst in copied:
        print(f"[release-build]   {dst}")

    build_utc = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
    tool_versions = {
        "node": read_version(["node", "--version"]),
        "cc": read_version(["cc", "--version"]),
        "make": read_version(["make", "--version"]),
        "python": read_version([sys.executable, "--version"]),
        "jq": read_version(["jq", "--version"]),
    }

    output_binary_arch = {
        "c/ps": binary_arch(ROOT / "c" / "ps"),
        "c/pscc": binary_arch(ROOT / "c" / "pscc"),
    }
    for bin_name, arch_info in output_binary_arch.items():
        print(f"[release-build] output binary architecture {bin_name}: {arch_info}")

    artifact_entries: list[dict[str, object]] = []
    for path in sorted(copied):
        rel = path.relative_to(DIST_DIR)
        artifact_entries.append(
            {
                "path": str(rel),
                "size": path.stat().st_size,
                "sha256": sha256_file(path),
            }
        )

    manifest = {
        "release_version": release_version,
        "release_name": release_name,
        "build_utc": build_utc,
        "nightly_mode": bool(args.nightly),
        "git_commit": git_commit(),
        "platform": {
            "system": platform.system(),
            "machine": platform.machine(),
            "host_arch_uname_m": host_arch,
            "target_arch": target_arch,
            "compiler_target_triple": target_triple,
            "python": platform.python_version(),
        },
        "tool_versions": tool_versions,
        "gates": gates,
        "output_binary_architecture": output_binary_arch,
        "artifacts": artifact_entries,
    }

    manifest_path = DIST_DIR / "manifest.json"
    manifest_path.write_text(json.dumps(manifest, indent=2, sort_keys=True) + "\n", encoding="utf-8")
    (release_dir / "manifest.json").write_text(json.dumps(manifest, indent=2, sort_keys=True) + "\n", encoding="utf-8")
    (REPORT_DIR / "latest.json").write_text(json.dumps(manifest, indent=2, sort_keys=True) + "\n", encoding="utf-8")

    print(f"[release-build] OK wrote {manifest_path}")
    print(f"[release-build] release directory: {release_dir}")
    return 0


if __name__ == "__main__":
    sys.exit(main())
